{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31509e62",
   "metadata": {},
   "source": [
    "# 플랫폼 업로드를 쉽게하기 위한 로컬 개발 코드\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): 빅데이터/인공지능 통합 플랫폼\n",
    "- 플랫폼 업로드를 쉽게하기 위하여 로컬에서 2개의 파일로 나누어 코드를 개발한다.\n",
    "- 파일 1_1: 전처리와 학습모델을 개발하는 코드, 전처리 객체나 성능이 검증된 학습모델 객체를 저장한다.\n",
    "- 파일 1_2: 학습모델을 통해 추론(예측)을 개발하는 코드, 전처리 객체나 학습모델 객체를 불러와서 추론을 수행한다. \n",
    "\n",
    "- 파일 1_1(파일명): 1_1_local_platform_iris_classification_preprocess_train_sklearn.ipynb\n",
    "- 파일 1_2(파일명): 1_2_local_platform_iris_classification_inference_sklearn.ipynb\n",
    "\n",
    "### 전처리 객체 또는 학습모델 객체\n",
    "- 전처리 객체나 학습모델 객쳬는 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "### 데이터 세트(학습 데이터/테스트 데이터)\n",
    "- 학습과 테스트에 사용되는 데이터를 나누어 관리한다.\n",
    "- 학습 데이터: dataset 폴더 아래에 저장하거나 dataset.zip 파일 형태로 저장한다.\n",
    "- 테스트 데이터: test_dataset 폴더 아래에 저장하거나 test_dataset.zip 파일 형태로 저장한다.\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. **데이터 세트 준비(Data Setup)**\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터 세트를 준비한다.\n",
    "\n",
    "2. **데이터 전처리(Data Preprocessing)**\n",
    "- 데이터 세트의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. **학습 모델 훈련(Train Model)**\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터 세트로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. **추론(Inference)**\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터 세트를 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02e254",
   "metadata": {},
   "source": [
    "# 아이리스 분류(Iris Classification)\n",
    "- 아이리스 품종 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e4185",
   "metadata": {},
   "source": [
    "### 머신러닝을 이용한 아이리스 품종 분류 워크플로우(workflow)\n",
    "- 1. 아이리스 데이터 파일(iris.csv) 얻기.\n",
    "- 2. 학습을 위한 데이터 전처리(훈련 데이터, 테스트 데이터).\n",
    "- 3. SVM을 이용한 모델 생성 및 훈련.\n",
    "- 4. 아이리스 품종 추론.\n",
    "\n",
    "### 아이리스 데이터 세트\n",
    "- 아이리스 데이터 세트에는 150개의 데이터 세트가 저장되어 있습니다.\n",
    "- 아이리스 데이터 세트는 꽃받침 길이, 꽃받침 폭, 꽃잎 길이, 꽃잎 폭 총 4개의 컬럼과 1개의 종 컬럼으로 구성되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593e7b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c645cdf",
   "metadata": {},
   "source": [
    "## **1. 데이터 세트 준비(Data Setup)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735c6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local에 저장된 아이리스 데이터 csv 파일을 읽어온다.\n",
    "source_path = './meta_data/dataset'\n",
    "df = pd.read_csv(source_path + '/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4e411",
   "metadata": {},
   "source": [
    "## **2. 데이터 전처리(Data Preprocessing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff09a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터: 추론 데이터 = 8 : 2.\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0aed4",
   "metadata": {},
   "source": [
    "## **3. 학습 모델 훈련(Train Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edac91e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# svm 형태로 모델을 만들고 학습.\n",
    "svm_clf = svm.SVC(kernel = 'linear').fit(x_train, y_train)\n",
    "# 정확도 평가.\n",
    "print(accuracy_score(y_test, svm_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1508f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 저장.\n",
    "with open('meta_data/iris_model.p', 'wb') as f:\n",
    "    pickle.dump(svm_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb007f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
