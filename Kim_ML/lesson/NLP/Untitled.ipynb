{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e758e10c-fd1e-4a07-b667-0057c7dc630f",
   "metadata": {},
   "source": [
    "# 텍스트 전처리\n",
    "- 패키지 설치\n",
    "    - NLTK : pip install nltk\n",
    "    - KoNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e73455-17b2-4921-878f-c9daa469c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55637c55-d927-4f16-b9c8-d3adc03c45f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef4af37-d1f2-4c08-a21b-dedde76b26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6181b8d2-184c-4c90-89d7-b67e3b27dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk LookupError\n",
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fe31d-0bb7-41b6-9688-b3161c55d48d",
   "metadata": {},
   "source": [
    "##  [1] 토큰화\n",
    "- 문장/ 문서를 의미를 지닌 작은 단위로 나뉘는 것\n",
    "- 나누어진 단어를 토큰(Token)이라 함.\n",
    "- 종류\n",
    "    - 문장 토큰화\n",
    "    - 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa93c647-2029-424d-8102-4b6e57cb9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3c361a0-fe6f-4fce-9656-27be55207e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_01='Caution: when tokenizing a Unicode string, make sure you are not using an encoded version of the string (it may be necessary to decode it first, e.g. with s.decode(\"utf8\").'\n",
    "\n",
    "raw_text_02=\"\"\"Return a tokenized copy of text, using NLTK’s recommended word tokenizer (currently an improved TreebankWordTokenizer along with PunktSentenceTokenizer for the specified language).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf65f988-c0a9-4f87-b92c-b2a7b3895b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caution', ':', 'when', 'tokenizing', 'a', 'Unicode', 'string', ',', 'make', 'sure', 'you', 'are', 'not', 'using', 'an', 'encoded', 'version', 'of', 'the', 'string', '(', 'it', 'may', 'be', 'necessary', 'to', 'decode', 'it', 'first', ',', 'e.g', '.', 'with', 's.decode', '(', '``', 'utf8', \"''\", ')', '.']\n"
     ]
    }
   ],
   "source": [
    "# 단어 단위 토큰화\n",
    "result_01=word_tokenize(raw_text_01)\n",
    "print(result_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720cb553-dc26-4f18-895d-176c0f6562cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caution: when tokenizing a Unicode string, make sure you are not using an encoded version of the string (it may be necessary to decode it first, e.g. with s.decode(\"utf8\").Return a tokenized copy of text, using NLTK’s recommended word tokenizer (currently an improved TreebankWordTokenizer along with PunktSentenceTokenizer for the specified language).\\n']\n"
     ]
    }
   ],
   "source": [
    "raw_text=[raw_text01 + raw_text_02]\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce8232-27ee-4181-a7d5-26c54dc699fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
