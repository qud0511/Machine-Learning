{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3b0069-671b-4f6e-8294-04721294ea72",
   "metadata": {},
   "source": [
    "## CNN(Convolution Neural Network)\n",
    "- 이미지, 영상 처리에 사용되는 신경망 모델\n",
    "- DNN의 한 분야\n",
    "- 텍스트 처리에도 사용되는 모델\n",
    "- 사용되는 Layer\n",
    "    * ConvXD : 이미지 형태 그대로 입력 받아 특징을 추출하는 레이어\n",
    "    * Polling : 특징맵에서 특징을 다시 추출하여 다운샘플링하는 레이어, 크기를 반으로 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b473c9c1-5206-423e-a0e9-183830ce82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import set_random_seed, plot_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9c5a93-3aba-4f90-bd96-b61cdddb6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W,b 고정하도록 seed 설정\n",
    "set_random_seed(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b91c9-27f8-4836-a595-c0c9a217e452",
   "metadata": {},
   "source": [
    "### [1] 데이터 준비 및 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca16bd4f-ffa8-4269-9bda-71853c37be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e2e21d-843f-431a-b909-e131e5b8d1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 28, 28), y_train.shape : (60000,)\n",
      "x_test.shape : (10000, 28, 28), y_train.shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train.shape : {x_train.shape}, y_train.shape : {y_train.shape}')\n",
    "print(f'x_test.shape : {x_test.shape}, y_train.shape : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529af95-dfdc-49ce-af29-5145a76e520c",
   "metadata": {},
   "source": [
    "## [2] 데이터 전처리 및 학습형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31f8e3d-b8dd-4404-8c28-7cd37ac504a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 => 픽셀 / 255.0\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44bd764-a796-4974-994d-10192c6ebdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv 레이어는 이미지의 채널 정보까지 입력\n",
    "x_train=x_train.reshape(-1, 28, 28, 1)\n",
    "x_test=x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a18705-74fe-44da-b3b3-fddefd21e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (60000, 28, 28, 1)\n",
      "x_test.shape : (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'x_test.shape : {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849df3ee-3f05-4e86-b4cd-d221d8b1078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 데이터 준비\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db1371d-7aaf-4ead-9aee-eb18704521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                 stratify=y_train,\n",
    "                                                 random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f7ac06-ede8-4fbd-a650-db2360c6f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'x_train.shape : {x_train.shape}, x_val.shape : {x_val.shape}, y_train.shape : {y_train.shape}, y_val.shape : {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e651e0-a4b5-41de-8989-d1b707a1ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (45000, 28, 28, 1)\n",
      "x_val.shape : (15000, 28, 28, 1)\n",
      "y_train.shape : (45000,)\n",
      "y_val.shape : (15000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'x_val.shape : {x_val.shape}')\n",
    "print(f'y_train.shape : {y_train.shape}')\n",
    "print(f'y_val.shape : {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365773a-609a-4116-a6a1-802661ac36e5",
   "metadata": {},
   "source": [
    "---\n",
    "## [3] 모델 구성 및 생성\n",
    "- 입력 형태 : 채널정보까지 포함 3차원 (28, 28, 1)\n",
    "- 출력 형태 : 0 ~ 9정수 확률값 10개 출력\n",
    "- 학습 방식 : 분류 - 다중분류\n",
    "- 전반부\n",
    "    * 이미지의 특징 추출\n",
    "        - Conv2D, MaxPoll2D\n",
    "- 후반부\n",
    "    * 이미지 데이터 학습\n",
    "        - Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218135d-acf9-4d10-835a-b11f963916d4",
   "metadata": {},
   "source": [
    "---\n",
    "## [3-1] 모델 구상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d67970-f1b2-4420-9285-7a0130dddb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8faebe78-6fe6-4472-8696-1221b1825709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 특징 추출 Layer => 첫번째 입력값 설정\n",
    "model.add(Conv2D(2, kernel_size=3, padding='same', input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "282b1038-b32d-4eee-a302-07e5b60afbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 특징 다른 샘플링 Layer => MaxPool2D\n",
    "model.add(MaxPool2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4cba022-5408-4f08-86a4-356abc2fff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원으로 데이터 형태 변환 Layer => Flatten\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f0c18e-1aa0-4f22-8bb1-2e1cba8a04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 => Node : 10개(0~9), activation : softmax\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e922fed-6b4e-41d1-8242-e065130f748f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 2)         20        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 2)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 392)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                3930      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,950\n",
      "Trainable params: 3,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d60c0b1-357b-4ad7-9f37-49877dc3e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, show_dtype=True) # to_file='cnn.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dfeea7-aaa4-4466-b13e-f2dff2d60b92",
   "metadata": {},
   "source": [
    "---\n",
    "## [3-2] 모델 생성\n",
    "- compile 메서드\n",
    "    * loss 손실 함수 => 다중이므로 sparse_categorical_crossentropy\n",
    "    * optimizer 최적화 방식 => adam\n",
    "    * metrics 평가항목 => accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3aee0db-7f71-4190-b4cb-2a12bfc54dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc77ae-dcb7-47f5-b9d2-638828527293",
   "metadata": {},
   "source": [
    "---\n",
    "## [3-3] 모델 학습\n",
    "- fit 메서드\n",
    "    * 학습 데이터, 라벨\n",
    "    * epochs : 학습횟수\n",
    "    * batch_size : 학습분량\n",
    "    * validation_data => (검증데이터, 검증라벨) -> 튜플로 담음, 검증데이터 직접 나눴으면 사용\n",
    "    * validation_split : 학습데이터의 일부 비율 자동으로? 설정(예 : 0.2)\n",
    "    * callback\n",
    "    * verbose : 학습 진행도 화면 출력 여부 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48bea0-fa3b-46d3-afe0-aea861ac3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.5255 - accuracy: 0.8132 - val_loss: 0.4259 - val_accuracy: 0.8509\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.4152 - accuracy: 0.8555 - val_loss: 0.4019 - val_accuracy: 0.8568\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3925 - accuracy: 0.8618 - val_loss: 0.3928 - val_accuracy: 0.8637\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.3796 - accuracy: 0.8679 - val_loss: 0.3992 - val_accuracy: 0.8597\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3741 - accuracy: 0.8680 - val_loss: 0.3880 - val_accuracy: 0.8664\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3668 - accuracy: 0.8708 - val_loss: 0.3935 - val_accuracy: 0.8625\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3625 - accuracy: 0.8723 - val_loss: 0.3900 - val_accuracy: 0.8647\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3581 - accuracy: 0.8738 - val_loss: 0.3765 - val_accuracy: 0.8727\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3538 - accuracy: 0.8740 - val_loss: 0.3750 - val_accuracy: 0.8735\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.3515 - accuracy: 0.8754 - val_loss: 0.3781 - val_accuracy: 0.8687\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.3486 - accuracy: 0.8766 - val_loss: 0.3726 - val_accuracy: 0.8731\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.3461 - accuracy: 0.8780 - val_loss: 0.3763 - val_accuracy: 0.8717\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3434 - accuracy: 0.8778 - val_loss: 0.3707 - val_accuracy: 0.8703\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3419 - accuracy: 0.8800 - val_loss: 0.3757 - val_accuracy: 0.8717\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3408 - accuracy: 0.8783 - val_loss: 0.3622 - val_accuracy: 0.8748\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.3393 - accuracy: 0.8801 - val_loss: 0.3828 - val_accuracy: 0.8677\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3373 - accuracy: 0.8798 - val_loss: 0.3677 - val_accuracy: 0.8763\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.3361 - accuracy: 0.8815 - val_loss: 0.3641 - val_accuracy: 0.8748\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.3343 - accuracy: 0.8815 - val_loss: 0.3729 - val_accuracy: 0.8709\n",
      "Epoch 20/30\n",
      " 710/9000 [=>............................] - ETA: 15s - loss: 0.3170 - accuracy: 0.8887"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=30, batch_size=5,\n",
    "                validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896016d-bf87-434c-8d64-ff236bb59613",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_val[0].reshape(28, 28), cmap='gray_r')\n",
    "plt.title(f'Label = {y_val[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa47167-f3b8-43d9-96a1-0618f07d19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 비교\n",
    "plt.plot(result.epoch, result.history['loss'],label='Train loss')\n",
    "plt.plot(result.epoch, result.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ca464-4f57-4b45-9ac9-940b346a6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy 비교\n",
    "plt.plot(result.epoch, result.history['accuracy'],label='Train accuracy')\n",
    "plt.plot(result.epoch, result.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bf3c4-a2cd-42ce-9282-46e8b6f09b58",
   "metadata": {},
   "source": [
    "---\n",
    "## [4] 테스트 평가\n",
    "- evaluate 메서드\n",
    "- 테스트 데이터, 테스트 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1741591-e876-41d5-982f-4627fa8b65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1b58c-4e36-4358-a977-40dd205f3471",
   "metadata": {},
   "source": [
    "---\n",
    "## [5] 테스트\n",
    "- 새로운 데이터로 하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d190f-0141-4d63-bf42-a0f72070eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(x_test[0].reshape(-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f5448-fc11-4861-b37d-0ee44af2949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y.round(2), predict_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf46e8-da75-472f-9ecc-2cfab0ca1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c0af1-dba0-4923-b4cf-8a6edc02ea15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
